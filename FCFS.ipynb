{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zfw6Va3p9cE_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "r2CdAXTAXJOI",
        "outputId": "0d82a74a-5112-4fd6-f483-106a097906cf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 124,\n  \"fields\": [\n    {\n      \"column\": \"Accel X\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4214826776981798,\n        \"min\": -0.9136,\n        \"max\": 0.8176,\n        \"num_unique_values\": 121,\n        \"samples\": [\n          0.445733,\n          0.067733,\n          0.1082667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accel Y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6125112840072526,\n        \"min\": -0.9770667,\n        \"max\": 0.9393333,\n        \"num_unique_values\": 123,\n        \"samples\": [\n          0.4273333,\n          0.391067,\n          -0.9472\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accel Z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.44025185531394595,\n        \"min\": -1.0190667,\n        \"max\": 0.906667,\n        \"num_unique_values\": 123,\n        \"samples\": [\n          0.0266667,\n          -0.5888,\n          0.402533\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gyro X\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.826429297757543,\n        \"min\": -14.493067,\n        \"max\": 11.0948,\n        \"num_unique_values\": 123,\n        \"samples\": [\n          -2.5097333,\n          8.997867,\n          -3.8924\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gyro Y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.369715156779045,\n        \"min\": -10.586933,\n        \"max\": 9.5464,\n        \"num_unique_values\": 122,\n        \"samples\": [\n          0.9405333,\n          -3.5148,\n          5.1296\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gyro Z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.079612023286063,\n        \"min\": -14.024667,\n        \"max\": 11.9236,\n        \"num_unique_values\": 123,\n        \"samples\": [\n          -1.7894667,\n          3.178533,\n          -1.553333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Fall\",\n          \"Not Fall\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-bd123201-57ca-48df-b765-c96a62698353\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accel X</th>\n",
              "      <th>Accel Y</th>\n",
              "      <th>Accel Z</th>\n",
              "      <th>Gyro X</th>\n",
              "      <th>Gyro Y</th>\n",
              "      <th>Gyro Z</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.106800</td>\n",
              "      <td>-0.899333</td>\n",
              "      <td>-0.311333</td>\n",
              "      <td>-4.862667</td>\n",
              "      <td>1.241467</td>\n",
              "      <td>-4.845467</td>\n",
              "      <td>Not Fall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.168800</td>\n",
              "      <td>-0.918667</td>\n",
              "      <td>-0.323200</td>\n",
              "      <td>-3.316533</td>\n",
              "      <td>1.119867</td>\n",
              "      <td>-5.003333</td>\n",
              "      <td>Not Fall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.806800</td>\n",
              "      <td>-0.015733</td>\n",
              "      <td>-0.033733</td>\n",
              "      <td>2.998667</td>\n",
              "      <td>1.668800</td>\n",
              "      <td>11.923600</td>\n",
              "      <td>Not Fall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.863467</td>\n",
              "      <td>-0.027733</td>\n",
              "      <td>-0.022933</td>\n",
              "      <td>4.955867</td>\n",
              "      <td>1.051333</td>\n",
              "      <td>11.309467</td>\n",
              "      <td>Not Fall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.108267</td>\n",
              "      <td>-0.962133</td>\n",
              "      <td>0.058267</td>\n",
              "      <td>-10.379600</td>\n",
              "      <td>9.546400</td>\n",
              "      <td>0.762400</td>\n",
              "      <td>Not Fall</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd123201-57ca-48df-b765-c96a62698353')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd123201-57ca-48df-b765-c96a62698353 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd123201-57ca-48df-b765-c96a62698353');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-14aa4af4-82eb-447b-9632-189ee6d93971\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-14aa4af4-82eb-447b-9632-189ee6d93971')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-14aa4af4-82eb-447b-9632-189ee6d93971 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    Accel X   Accel Y   Accel Z     Gyro X    Gyro Y     Gyro Z    Target\n",
              "0 -0.106800 -0.899333 -0.311333  -4.862667  1.241467  -4.845467  Not Fall\n",
              "1 -0.168800 -0.918667 -0.323200  -3.316533  1.119867  -5.003333  Not Fall\n",
              "2 -0.806800 -0.015733 -0.033733   2.998667  1.668800  11.923600  Not Fall\n",
              "3 -0.863467 -0.027733 -0.022933   4.955867  1.051333  11.309467  Not Fall\n",
              "4  0.108267 -0.962133  0.058267 -10.379600  9.546400   0.762400  Not Fall"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('/content/train-3.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "5hu5r-PGsjyU",
        "outputId": "51223d03-1713-4a74-be5d-6e794123a171"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accel X</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Accel Y</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Accel Z</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gyro X</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gyro Y</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gyro Z</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Target</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "Accel X    float64\n",
              "Accel Y    float64\n",
              "Accel Z    float64\n",
              "Gyro X     float64\n",
              "Gyro Y     float64\n",
              "Gyro Z     float64\n",
              "Target      object\n",
              "dtype: object"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "D9SQou3bsMRB"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Handle missing values by replacing with column mean (numerical columns only)\n",
        "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
        "df[numeric_columns] = df[numeric_columns].apply(lambda col: col.fillna(col.mean()))\n",
        "\n",
        "# Normalize numeric columns (min-max scaling)\n",
        "def normalize_column(col):\n",
        "    return (col - col.min()) / (col.max() - col.min())\n",
        "\n",
        "df[numeric_columns] = df[numeric_columns].apply(normalize_column)\n",
        "\n",
        "# Encode target column (e.g., Not Fall -> 0, Fall -> 1)\n",
        "df['Target'] = df['Target'].apply(lambda x: 0 if x == 'Not Fall' else 1)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X = df.drop('Target', axis=1)\n",
        "y = df['Target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYRw-U42s1jm",
        "outputId": "2891cc4c-8a25-4390-afd6-5138a5c26f77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique values in y_train: [0 1]\n",
            "Data type of y_train: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Unique values in y_train:\", np.unique(y_train))\n",
        "print(\"Data type of y_train:\", y_train.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K971yY8GttVM",
        "outputId": "9e8057c6-fcf6-4ab0-8c5a-f4850acabc31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (99, 6)\n",
            "X_test shape: (25, 6)\n",
            "y_train shape: (99,)\n",
            "y_test shape: (25,)\n"
          ]
        }
      ],
      "source": [
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4y7jLs3Lj4li"
      },
      "outputs": [],
      "source": [
        "# Dense Layer\n",
        "class Layer_Dense:\n",
        "\n",
        "    # Layer initialization\n",
        "    def __init__(self, n_inputs, n_neurons,\n",
        "                 weight_regularizer_l1=0, weight_regularizer_l2=0,\n",
        "                 bias_regularizer_l1=0, bias_regularizer_l2=0):\n",
        "        # Initialize weights and biases\n",
        "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
        "        self.biases = np.zeros((1, n_neurons))\n",
        "        # Set regularization strength\n",
        "        self.weight_regularizer_l1 = weight_regularizer_l1\n",
        "        self.weight_regularizer_l2 = weight_regularizer_l2\n",
        "        self.bias_regularizer_l1 = bias_regularizer_l1\n",
        "        self.bias_regularizer_l2 = bias_regularizer_l2\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs, training):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "        # Calculate output values from inputs, weights and biases\n",
        "        self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Gradients on parameters\n",
        "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
        "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
        "\n",
        "\n",
        "        # Gradients on regularization\n",
        "        # L1 on weights\n",
        "        if self.weight_regularizer_l1 > 0:\n",
        "            dL1 = np.ones_like(self.weights)\n",
        "            dL1[self.weights < 0] = -1\n",
        "            self.dweights += self.weight_regularizer_l1 * dL1\n",
        "        # L2 on weights\n",
        "        if self.weight_regularizer_l2 > 0:\n",
        "            self.dweights += 2 * self.weight_regularizer_l2 * \\\n",
        "                             self.weights\n",
        "        # L1 on biases\n",
        "        if self.bias_regularizer_l1 > 0:\n",
        "            dL1 = np.ones_like(self.biases)\n",
        "            dL1[self.biases < 0] = -1\n",
        "            self.dbiases += self.bias_regularizer_l1 * dL1\n",
        "        # L2 on biases\n",
        "        if self.bias_regularizer_l2 > 0:\n",
        "            self.dbiases += 2 * self.bias_regularizer_l2 * \\\n",
        "                            self.biases\n",
        "\n",
        "        # Gradient on values\n",
        "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
        "\n",
        "    # Retrieve layer parameters\n",
        "    def get_parameters(self):\n",
        "        return self.weights, self.biases\n",
        "\n",
        "    # Set weights and biases in a layer instance\n",
        "    def set_parameters(self, weights, biases):\n",
        "        self.weights = weights\n",
        "        self.biases = biases\n",
        "\n",
        "\n",
        "# Dropout\n",
        "class Layer_Dropout:\n",
        "\n",
        "    # Init\n",
        "    def __init__(self, rate):\n",
        "        # Store rate, we invert it as for example for dropout\n",
        "        # of 0.1 we need success rate of 0.9\n",
        "        self.rate = 1 - rate\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs, training):\n",
        "        # Save input values\n",
        "        self.inputs = inputs\n",
        "\n",
        "\n",
        "        # If not in the training mode - return values\n",
        "        if not training:\n",
        "            self.output = inputs.copy()\n",
        "            return\n",
        "\n",
        "        # Generate and save scaled mask\n",
        "        self.binary_mask = np.random.binomial(1, self.rate,\n",
        "                           size=inputs.shape) / self.rate\n",
        "        # Apply mask to output values\n",
        "        self.output = inputs * self.binary_mask\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Gradient on values\n",
        "        self.dinputs = dvalues * self.binary_mask\n",
        "\n",
        "\n",
        "# Input \"layer\"\n",
        "class Layer_Input:\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs, training):\n",
        "        self.output = inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "o1fwDJsUyTCW"
      },
      "outputs": [],
      "source": [
        "class Activation_ReLU:\n",
        "    # Forward pass\n",
        "    def forward(self, inputs, training):\n",
        "        # Save input values for use during backpropagation\n",
        "        self.inputs = inputs\n",
        "        self.output = np.maximum(0, inputs)\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Make a copy of the gradients\n",
        "        self.dinputs = dvalues.copy()\n",
        "        # Zero gradient where input values were negative\n",
        "        self.dinputs[self.inputs <= 0] = 0\n",
        "\n",
        "    # Predictions method (used for inference)\n",
        "    def predictions(self, outputs):\n",
        "        return outputs\n",
        "\n",
        "\n",
        "# Softmax Activation\n",
        "class Activation_Softmax:\n",
        "\n",
        "    def forward(self, inputs, training):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "        # Shift values to prevent overflow\n",
        "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
        "        # Normalize probabilities\n",
        "        self.output = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
        "\n",
        "    def backward(self, dvalues):\n",
        "        # Create an uninitialized array\n",
        "        self.dinputs = np.empty_like(dvalues)\n",
        "\n",
        "        # Enumerate outputs and gradients\n",
        "        for index, (single_output, single_dvalues) in enumerate(zip(self.output, dvalues)):\n",
        "            # Flatten output array\n",
        "            single_output = single_output.reshape(-1, 1)\n",
        "            # Calculate Jacobian matrix of the output\n",
        "            jacobian_matrix = np.diagflat(single_output) - np.dot(single_output, single_output.T)\n",
        "            # Calculate sample-wise gradient\n",
        "            self.dinputs[index] = np.dot(jacobian_matrix, single_dvalues)\n",
        "\n",
        "    def predictions(self, outputs):\n",
        "        # Return index of maximum probability\n",
        "        return np.argmax(outputs, axis=1)\n",
        "\n",
        "# Sigmoid Activation\n",
        "class Activation_Sigmoid:\n",
        "\n",
        "    def forward(self, inputs, training):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "        # Apply sigmoid function\n",
        "        self.output = 1 / (1 + np.exp(-inputs))\n",
        "\n",
        "    def backward(self, dvalues):\n",
        "        # Derivative of sigmoid\n",
        "        self.dinputs = dvalues * (1 - self.output) * self.output\n",
        "\n",
        "    def predictions(self, outputs):\n",
        "        # Return binary classification\n",
        "        return (outputs > 0.5) * 1\n",
        "\n",
        "# Tanh Activation\n",
        "class Activation_Tanh:\n",
        "\n",
        "    def forward(self, inputs, training):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "        # Apply Tanh activation\n",
        "        self.output = np.tanh(inputs)\n",
        "\n",
        "    def backward(self, dvalues):\n",
        "        # Derivative of Tanh\n",
        "        self.dinputs = dvalues * (1 - self.output ** 2)\n",
        "\n",
        "    def predictions(self, outputs):\n",
        "        # Return predictions directly\n",
        "        return outputs\n",
        "\n",
        "# Linear Activation\n",
        "class Activation_Linear:\n",
        "\n",
        "    def forward(self, inputs, training):\n",
        "        # Just remember values\n",
        "        self.inputs = inputs\n",
        "        self.output = inputs\n",
        "\n",
        "    def backward(self, dvalues):\n",
        "        # Derivative is 1; pass through gradients\n",
        "        self.dinputs = dvalues.copy()\n",
        "\n",
        "    def predictions(self, outputs):\n",
        "        # Return predictions directly\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ox1ae4g-ZMCN"
      },
      "outputs": [],
      "source": [
        "class Optimizer_Adam:\n",
        "\n",
        "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7, beta_1=0.9, beta_2=0.999):\n",
        "        \"\"\"\n",
        "        Initialize the Adam optimizer.\n",
        "\n",
        "        Parameters:\n",
        "        - learning_rate: Initial learning rate for the optimizer.\n",
        "        - decay: Learning rate decay factor.\n",
        "        - epsilon: Small value to prevent division by zero.\n",
        "        - beta_1: Exponential decay rate for the first moment estimates.\n",
        "        - beta_2: Exponential decay rate for the second moment estimates.\n",
        "        \"\"\"\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.epsilon = epsilon\n",
        "        self.beta_1 = beta_1\n",
        "        self.beta_2 = beta_2\n",
        "\n",
        "    def pre_update_params(self):\n",
        "        \"\"\"\n",
        "        Update the learning rate if decay is applied.\n",
        "        \"\"\"\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    def update_params(self, layer):\n",
        "        \"\"\"\n",
        "        Update parameters for the given layer using Adam optimization.\n",
        "\n",
        "        Parameters:\n",
        "        - layer: A layer object containing weights and biases.\n",
        "        \"\"\"\n",
        "        # If layer does not have moment or cache arrays, initialize them\n",
        "        if not hasattr(layer, 'weight_momentums'):\n",
        "            layer.weight_momentums = np.zeros_like(layer.weights)\n",
        "            layer.weight_cache = np.zeros_like(layer.weights)\n",
        "            layer.bias_momentums = np.zeros_like(layer.biases)\n",
        "            layer.bias_cache = np.zeros_like(layer.biases)\n",
        "\n",
        "        # Update momentum with current gradients\n",
        "        layer.weight_momentums = self.beta_1 * layer.weight_momentums + (1 - self.beta_1) * layer.dweights\n",
        "        layer.bias_momentums = self.beta_1 * layer.bias_momentums + (1 - self.beta_1) * layer.dbiases\n",
        "\n",
        "        # Correct momentum for bias correction\n",
        "        weight_momentums_corrected = layer.weight_momentums / (1 - self.beta_1 ** (self.iterations + 1))\n",
        "        bias_momentums_corrected = layer.bias_momentums / (1 - self.beta_1 ** (self.iterations + 1))\n",
        "\n",
        "        # Update cache with squared gradients\n",
        "        layer.weight_cache = self.beta_2 * layer.weight_cache + (1 - self.beta_2) * layer.dweights ** 2\n",
        "        layer.bias_cache = self.beta_2 * layer.bias_cache + (1 - self.beta_2) * layer.dbiases ** 2\n",
        "\n",
        "        # Correct cache for bias correction\n",
        "        weight_cache_corrected = layer.weight_cache / (1 - self.beta_2 ** (self.iterations + 1))\n",
        "        bias_cache_corrected = layer.bias_cache / (1 - self.beta_2 ** (self.iterations + 1))\n",
        "\n",
        "        # Update weights and biases\n",
        "        layer.weights += -self.current_learning_rate * weight_momentums_corrected / (np.sqrt(weight_cache_corrected) + self.epsilon)\n",
        "        layer.biases += -self.current_learning_rate * bias_momentums_corrected / (np.sqrt(bias_cache_corrected) + self.epsilon)\n",
        "\n",
        "    def post_update_params(self):\n",
        "        \"\"\"\n",
        "        Increment the iteration count after updating the parameters.\n",
        "        \"\"\"\n",
        "        self.iterations += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ECUUFdtqvMgg"
      },
      "outputs": [],
      "source": [
        "# Cross-entropy loss\n",
        "class Loss_CategoricalCrossentropy:\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        # Clip data to prevent division by 0\n",
        "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "\n",
        "        # For sparse labels\n",
        "        if len(y_true.shape) == 1:\n",
        "            correct_confidences = y_pred_clipped[range(len(y_pred)), y_true]\n",
        "        # For one-hot encoded labels\n",
        "        elif len(y_true.shape) == 2:\n",
        "            correct_confidences = np.sum(y_pred_clipped * y_true, axis=1)\n",
        "\n",
        "        return -np.log(correct_confidences)\n",
        "\n",
        "    def backward(self, dvalues, y_true):\n",
        "        samples = len(dvalues)\n",
        "        labels = len(dvalues[0])\n",
        "\n",
        "        # If labels are sparse, turn them into one-hot encoding\n",
        "        if len(y_true.shape) == 1:\n",
        "            y_true = np.eye(labels)[y_true]\n",
        "\n",
        "        # Gradient\n",
        "        self.dinputs = -y_true / dvalues\n",
        "        self.dinputs = self.dinputs / samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kg--RhDvvN7H"
      },
      "outputs": [],
      "source": [
        "\"\"\"class Accuracy_Categorical:\n",
        "\n",
        "    def calculate(self, y_pred, y_true):\n",
        "        # Convert predictions to class labels\n",
        "        predictions = np.argmax(y_pred, axis=1)\n",
        "        if len(y_true.shape) == 2:\n",
        "            y_true = np.argmax(y_true, axis=1)\n",
        "        return np.mean(predictions == y_true)\"\"\"\n",
        "\n",
        "class Accuracy_Binary:\n",
        "    def calculate(self, y_pred, y_true):\n",
        "        # Convert predictions to binary class labels (ngưỡng 0.5)\n",
        "        predictions = (y_pred >= 0.5).astype(int)\n",
        "        return np.mean(predictions == y_true)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8LaJs4CLvQXq"
      },
      "outputs": [],
      "source": [
        "class Model:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "        self.loss = None\n",
        "        self.optimizer = None\n",
        "        self.accuracy = None\n",
        "\n",
        "    def add(self, layer):\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    def set(self, *, loss, optimizer, accuracy):\n",
        "        self.loss = loss\n",
        "        self.optimizer = optimizer\n",
        "        self.accuracy = accuracy\n",
        "\n",
        "    def forward(self, X, training):\n",
        "        self.layers[0].forward(X, training)\n",
        "        for i in range(1, len(self.layers)):\n",
        "            self.layers[i].forward(self.layers[i - 1].output, training)\n",
        "\n",
        "    def backward(self, y_pred, y_true):\n",
        "    # Calculate gradient for the loss\n",
        "        self.loss.backward(y_pred, y_true)\n",
        "\n",
        "        # Iterate over layers in reverse order\n",
        "        for i in reversed(range(len(self.layers))):\n",
        "            # For the last layer, pass the loss gradient\n",
        "            if i == len(self.layers) - 1:\n",
        "                self.layers[i].backward(self.loss.dinputs)\n",
        "            else:\n",
        "                # Pass the gradient from the next layer\n",
        "                self.layers[i].backward(self.layers[i + 1].dinputs)\n",
        "\n",
        "    def summary(self):\n",
        "        print(\"Model Summary\")\n",
        "        print(\"=\" * 50)\n",
        "        total_params = 0\n",
        "        total_flops = 0\n",
        "\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer, Layer_Dense):\n",
        "            # Parameters = weights + biases\n",
        "                params = layer.weights.size + layer.biases.size\n",
        "                total_params += params\n",
        "            # FLOPs = (inputs * outputs) + outputs (for biases)\n",
        "                flops = layer.weights.size + layer.biases.size\n",
        "                total_flops += flops\n",
        "                print(f\"Dense Layer: {layer.weights.shape[0]} -> {layer.weights.shape[1]}, Params: {params}, FLOPs: {flops}\")\n",
        "            elif isinstance(layer, Activation_ReLU):\n",
        "                print(\"Activation Layer: ReLU\")\n",
        "            elif isinstance(layer, Activation_Softmax):\n",
        "                print(\"Activation Layer: Softmax\")\n",
        "            elif isinstance(layer, Layer_Dropout):\n",
        "                print(\"Dropout Layer\")\n",
        "            else:\n",
        "                print(f\"Layer: {type(layer).__name__}\")\n",
        "\n",
        "        print(\"=\" * 50)\n",
        "        print(f\"Total Parameters: {total_params}\")\n",
        "        print(f\"Total FLOPs: {total_flops}\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "\n",
        "    def train(self, X, y, epochs, batch_size, lr_scheduler=None):\n",
        "        for epoch in range(epochs):\n",
        "            # Update learning rate if a scheduler is provided\n",
        "            if lr_scheduler:\n",
        "                self.optimizer.current_learning_rate = lr_scheduler(epoch)\n",
        "\n",
        "            # Loop over mini-batches\n",
        "            for batch_start in range(0, len(X), batch_size):\n",
        "                batch_end = batch_start + batch_size\n",
        "                batch_X = X[batch_start:batch_end]\n",
        "                batch_y = y[batch_start:batch_end]\n",
        "\n",
        "                # Forward pass\n",
        "                self.forward(batch_X, training=True)\n",
        "\n",
        "                # Calculate loss\n",
        "                loss = np.mean(self.loss.forward(self.layers[-1].output, batch_y))\n",
        "\n",
        "                # Backward pass\n",
        "                self.backward(self.layers[-1].output, batch_y)\n",
        "\n",
        "                # Update weights\n",
        "                for layer in self.layers:\n",
        "                    if hasattr(layer, 'weights'):\n",
        "                        self.optimizer.update_params(layer)\n",
        "\n",
        "            # Calculate accuracy after each epoch\n",
        "            accuracy = self.accuracy.calculate(self.layers[-1].output, batch_y)\n",
        "\n",
        "            # Print metrics for the epoch\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "D_goxJSwvXSl",
        "outputId": "b719c46c-fe9b-42d0-93e7-40565abb89ae"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (3,) (3,2) ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-68ad11a09444>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr_schedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-a8fdd600d481>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, epochs, batch_size, lr_scheduler)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# Calculate accuracy after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;31m# Print metrics for the epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-ec97cc1b467a>\u001b[0m in \u001b[0;36mcalculate\u001b[0;34m(self, y_pred, y_true)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Convert predictions to binary class labels (ngưỡng 0.5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2170\u001b[0m     ):\n\u001b[0;32m-> 2171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marraylike\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_ufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2173\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36marray_ufunc\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;31m# for binary ops, use our custom dunder methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_dispatch_ufunc_to_dunder_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mops_dispatch.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__eq__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__ne__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6117\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6119\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_na_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         if not is_cmp and (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;31m# error: \"None\" not callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_TEST_MODE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0m_store_test_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,) (3,2) "
          ]
        }
      ],
      "source": [
        "# Initialize the model\n",
        "model = Model()\n",
        "\n",
        "# Add layers to the model\n",
        "model.add(Layer_Dense(n_inputs=X_train.shape[1], n_neurons=16))\n",
        "model.add(Activation_ReLU())\n",
        "model.add(Layer_Dense(n_inputs=16, n_neurons=32))\n",
        "model.add(Activation_ReLU())\n",
        "model.add(Layer_Dense(n_inputs=32, n_neurons=1))  # Single output for binary classification\n",
        "model.add(Activation_Sigmoid())  # Use sigmoid for binary classification\n",
        "\n",
        "# Set loss, optimizer, and accuracy\n",
        "model.set(\n",
        "    loss=Loss_BinaryCrossentropy(),\n",
        "    optimizer=Optimizer_Adam(learning_rate=0.001),\n",
        "    accuracy=Accuracy_Binary()\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.train(X_train.values, y_train.values.reshape(-1, 1), epochs=50, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O3Nd6qP2dKP",
        "outputId": "96e28c50-bd87-4428-bcb9-07eec69a8235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Summary\n",
            "==================================================\n",
            "Dense Layer: 6 -> 16, Params: 112, FLOPs: 112\n",
            "Activation Layer: ReLU\n",
            "Dense Layer: 16 -> 32, Params: 544, FLOPs: 544\n",
            "Activation Layer: ReLU\n",
            "Dense Layer: 32 -> 2, Params: 66, FLOPs: 66\n",
            "Activation Layer: Softmax\n",
            "==================================================\n",
            "Total Parameters: 722\n",
            "Total FLOPs: 722\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
